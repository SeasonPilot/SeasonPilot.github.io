Question:

Reply in Chinese (Simplified).
The following is the text content of a web page, analyze the core content and summarize:
Configuring a connection pool is something that developers often get wrong. There are several, possibly counter-intuitive for some, principles that need to be understood when configuring the pool.10,000 Simultaneous Front-End UsersImagine that you have a website that while maybe not Facebook-scale still often has 10,000 users making database requests simultaneously -- accounting for some 20,000 transactions per second. How big should your connection pool be? You might be surprised that the question is not how big but rather how small!Watch this short video from the Oracle Real-World Performance group for an eye-opening demonstration (~10 min.):{Spoiler Alert} if you didn't watch the video. Oh come on! Watch it then come back here.You can see from the video that reducing the connection pool size alone, in the absence of any other change, decreased the response times of the application from ~100ms to ~2ms -- over 50x improvement.But why?We seem to have understood in other parts of computing recently that less is more. Why is it that with only 4-threads an nginx web-server can substantially out-perform an Apache web-server with 100 processes? Isn't it obvious if you think back to Computer Science 101?Even a computer with one CPU core can "simultaneously" support dozens or hundreds of threads. But we all [should] know that this is merely a trick by the operating system though the magic of time-slicing. In reality, that single core can only execute one thread at a time; then the OS switches contexts and that core executes code for another thread, and so on. It is a basic Law of Computing that given a single CPU resource, executing A and B sequentially will always be faster than executing A and B "simultaneously" through time-slicing. Once the number of threads exceeds the number of CPU cores, you're going slower by adding more threads, not faster.That is almost true...Limited ResourcesIt is not quite as simple as stated above, but it's close. There are a few other factors at play. When we look at what the major bottlenecks for a database are, they can be summarized as three basic categories: CPU, Disk, Network. We could add Memory in there, but compared to Disk and Network there are several orders of magnitude difference in bandwidth.If we ignored Disk and Network it would be simple. On a server with 8 computing cores, setting the number of connections to 8 would provide optimal performance, and anything beyond this would start slowing down due to the overhead of context switching. But we cannot ignore Disk and Network. Databases typically store data on a Disk, which traditionally is comprised of spinning plates of metal with read/write heads mounted on a stepper-motor driven arm. The read/write heads can only be in one place at a time (reading/writing data for a single query) and must "seek" to a new location to read/write data for a different query. So there is a seek-time cost, and also a rotational cost whereby the disk has to wait for the data to "come around again" on the platter to be read/written. Caching of course helps here, but the principle still applies.During this time ("I/O wait"), the connection/query/thread is simply "blocked" waiting for the disk. And it is during this time that the OS could put that CPU resource to better use by executing some more code for another thread. So, because threads become blocked on I/O, we can actually get more work done by having a number of connections/threads that is greater than the number of physical computing cores.How many more? We shall see. The question of how many more also depends on the disk subsystem, because newer SSD drives do not have a "seek time" cost or rotational factors to deal with. Don't be tricked into thinking, "SSDs are faster and therefore I can have more threads". That is exactly 180 degrees backwards. Faster, no seeks, no rotational delays means less blocking and therefore fewer threads [closer to core count] will perform better than more threads. More threads only perform better when blocking creates opportunities for executing.Network is similar to disk. Writing data out over the wire, through the ethernet interface, can also introduce blocking when the send/receive buffers fill up and stall. A 10-Gig interface is going to stall less than Gigabit ethernet, which will stall less than a 100-megabit. But network is a 3rd place runner in terms of resource blocking and some people often omit it from their calculations.Here's another chart to break up the wall of text.You can see in the above PostgreSQL benchmark that TPS rates start to flatten out at around 50 connections. And in Oracle's video above they showed dropping the connections from 2048 down to just 96. We would say that even 96 is probably too high, unless you're looking at a 16 or 32-core box.The FormulaThe formula below is provided by the PostgreSQL project as a starting point, but we believe it will be largely applicable across databases. You should test your application, i.e. simulate expected load, and try different pool settings around this starting point:connections = ((core_count * 2) + effective_spindle_count)
A formula which has held up pretty well across a lot of benchmarks for years is
that for optimal throughput the number of active connections should be somewhere
near ((core_count * 2) + effective_spindle_count). Core count should not include
HT threads, even if hyperthreading is enabled. Effective spindle count is zero if
the active data set is fully cached, and approaches the actual number of spindles
as the cache hit rate falls. ... There hasn't been any analysis so far regarding
how well the formula works with SSDs.
Guess what that means? Your little 4-Core i7 server with one hard disk should be running a connection pool of: 9 = ((4 * 2) + 1). Call it 10 as a nice round number. Seem low? Give it a try, we'd wager that you could easily handle 3000 front-end users running simple queries at 6000 TPS on such a setup. If you run load tests, you will probably see TPS rates starting to fall, and front-end response times starting to climb, as you push the connection pool much past 10 (on that given hardware).Axiom: You want a small pool, saturated with threads waiting for connections.If you have 10,000 front-end users, having a connection pool of 10,000 would be shear insanity. 1000 still horrible. Even 100 connections, overkill. You want a small pool of a few dozen connections at most, and you want the rest of the application threads blocked on the pool awaiting connections. If the pool is properly tuned it is set right at the limit of the number of queries the database is capable of processing simultaneously -- which is rarely much more than (CPU cores * 2) as noted above.We never cease to amaze at the in-house web applications we've encountered, with a few dozen front-end users performing periodic activity, and a connection pool of 100 connections. Don't over-provision your database."Pool-locking"The prospect of "pool-locking" has been raised with respect to single actors that acquire many connections. This is largely an application-level issue. Yes, increasing the pool size can alleviate lockups in these scenarios, but we would urge you to examine first what can be done at the application level before enlarging the pool.The calculation of pool size in order to avoid deadlock is a fairly simple resource allocation formula:   pool size = Tn x (Cm - 1) + 1Where Tn is the maximum number of threads, and Cm is the maximum number of simultaneous connections held by a single thread.For example, imagine three threads (Tn=3), each of which requires four connections to perform some task (Cm=4). The pool size required to ensure that deadlock is never possible is:   pool size = 3 x (4 - 1) + 1 = 10Another example, you have a maximum of eight threads (Tn=8), each of which requires three connections to perform some task (Cm=3). The pool size required to ensure that deadlock is never possible is:   pool size = 8 x (3 - 1) + 1 = 17👉 This is not necessarily the optimal pool size, but the minimum required to avoid deadlock.👉 In some environments, using a JTA (Java Transaction Manager) can dramatically reduce the number of connections required by returning the same Connection from getConnection() to a thread that is already holding a Connection in the current transaction.Caveat LectorPool sizing is ultimately very specific to deployments.For example, systems with a mix of long running transactions and very short transactions are generally the most difficult to tune with any connection pool. In those cases, creating two pool instances can work well (eg. one for long-running jobs, another for "realtime" queries).In systems with primarily long running transactions, there is often an "outside" constraint on the number of connections needed -- such as a job execution queue that only allows a certain number of jobs to run at once. In these cases, the job queue size should be "right-sized" to match the pool (rather than the other way around).

Answer:

回复中文（简体）。
以下是一个网页的文本内容，分析核心内容并总结：
配置连接池是开发者经常弄错的事情。在配置连接池时，需要理解一些可能与直觉相反的原则。1万个同时在线的前端用户假设你有一个网站，虽然不是Facebook那样的规模，但仍然经常有1万个用户同时发出数据库请求——相当于每秒2万次事务。你的连接池应该有多大？你可能会惊讶，问题不是多大而是多小！观看这段来自Oracle实际性能团队的短视频，看看令人大开眼界的演示（约10分钟）：{剧透警告}如果你没有看视频。哦，拜托！看完再回来吧。你可以从视频中看到，仅仅减少连接池的大小，在没有任何其他改变的情况下，就将应用程序的响应时间从约100毫秒降低到约2毫秒——超过50倍的提升。但为什么呢？我们似乎在计算机的其他方面最近理解了少即是多。为什么一个只有4个线程的nginx web服务器可以大幅超过一个有100个进程的Apache web服务器呢？如果你回想一下计算机科学101课程，这不是很明显吗？即使一个只有一个CPU核心的计算机也可以“同时”支持几十个或几百个线程。但我们都[应该]知道，这只是操作系统通过时间切片的魔法实现的。实际上，那个单核只能一次执行一个线程的代码；然后操作系统切换上下文，那个核就执行另一个线程的代码，依此类推。这是一个基本的计算定律，给定一个单一的CPU资源，顺序执行A和B总是比通过时间切片“同时”执行A和B要快。一旦线程数超过了CPU核心数，你就会因为增加了更多的线程而变慢，而不是变快。这几乎是正确的...有限资源这并不像上面说的那么简单，但也差不多。还有一些其他因素在起作用。当我们看看数据库的主要瓶颈是什么时，它们可以归纳为三个基本类别：CPU、磁盘、网络。我们可以把内存也加进去，但与磁盘和网络相比，内存在带宽方面有几个数量级的差异。如果我们忽略磁盘和网络，那就很简单了。在一个有8个计算核心的服务器上，将连接数设置为8将提供最佳性能，而超过这个数目将开始因为上下文切换的开销而变慢。但我们不能忽略磁盘和网络。数据库通常将数据存储在磁盘上，传统上磁盘由旋转的金属盘片和安装在步进电机驱动臂上的读/写头组成。读/写头只能在一个地方（为单个查询读/写数据），并且必须“寻找”新位置来为另一个查询读/写数据。所以有一个寻找时间成本，还有一个旋转成本，即磁盘必须等待数据“再次绕过”盘片才能被读/写。缓存当然可以帮助这里，但原理仍然适用。在这段时间（“I/O等待”）

<hr/>

Question:

继续

Answer:

继续。
连接/查询/线程只是“阻塞”等待磁盘。在这段时间里，操作系统可以通过为另一个线程执行更多的代码来更好地利用那个CPU资源。所以，因为线程被I/O阻塞了，我们实际上可以通过让连接/线程的数量大于物理计算核心的数量来完成更多的工作。多少更多？我们将看到。更多的数量也取决于磁盘子系统，因为新的SSD驱动器没有“寻找时间”成本或旋转因素要处理。不要被骗了，认为“SSD更快，所以我可以有更多的线程”。这完全是反过来的。更快，没有寻找，没有旋转延迟意味着更少的阻塞，因此更少的线程[接近核心数]会比更多的线程表现得更好。只有当阻塞为执行其他线程的代码创造了机会时，更多的线程才会表现得更好。网络与磁盘类似。通过以太网接口将数据写出到网线上，也会在发送/接收缓冲区填满并停顿时引入阻塞。10-Gig接口会比千兆以太网停顿得少，千兆以太网会比100兆停顿得少。但网络是资源阻塞方面的第三名选手，有些人经常忽略它在他们的计算中。下面是另一个图表来打破文字的墙壁。你可以在上面的PostgreSQL基准测试中看到，TPS率在大约50个连接时开始平坦。而在Oracle的视频中，他们显示将连接数从2048降低到96。我们会说即使是96也可能太高了，除非你在看一个16或32核的盒子。公式下面的公式是由PostgreSQL项目提供的一个起点，但我们相信它在很大程度上适用于各种数据库。你应该测试你的应用程序，即模拟预期的负载，并尝试围绕这个起点调整不同的池设置：connections = ((core_count * 2) + effective_spindle_count)
多年来，在很多基准测试中表现良好的一个公式是
为了获得最佳吞吐量，活跃连接数应该在
((core_count * 2) + effective_spindle_count)附近。核心数不应包括HT线程，
即使启用了超线程。有效磁盘数是零，如果活跃数据集完全缓存，
并且随着缓存命中率下降而接近实际磁盘数。
...目前还没有关于这个公式如何适用于SSD的分析。
你知道这意味着什么吗？你那台小小的4核i7服务器，带着一块硬盘，应该运行一个连接池：9 = ((4 * 2) + 1)。取个10作为一个整数吧。看起来低吗？试一试吧，我们打赌你可以轻松地用这样的设置来处理3000个前端用户运行简单查询，在6000 TPS上。如果你运行负载测试，你可能会看到TPS率开始下降，前端响应时间开始上升，当你把连接池推过10（在那个给定的硬件上）时。公理：你想要一个小池子，里面有等待连接的线程。如果你有1万个前端用户，拥有1万

<hr/>

Question:

继续

Answer:

继续。
个连接，你会有1万个线程，每个线程都在等待磁盘。这是浪费CPU资源的一种方式。如果你有一个小池子，比如10个连接，你会有10个线程，每个线程都在等待磁盘。这样，操作系统可以更有效地利用CPU资源，而不是在上下文切换上浪费时间。当然，如果你的查询很复杂，需要很长时间才能完成，那么你可能需要增加连接池的大小，以便为更多的前端用户提供服务。但是，如果你的查询很简单，只需要几毫秒就能完成，那么你可能会发现一个小池子就足够了。这就是为什么你应该测试你的应用程序，并根据实际的负载和响应时间来调整连接池的大小。你还有什么问题吗？😊


<hr/>

